{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Búsquedas semánticas con películas\n",
    "\n",
    "## Entorno:\n",
    "\n",
    "```shellscript\n",
    "docker run -p 6333:6333 -p 6334:6334 -v $(pwd)/q_storage:/qdrant/storage:z qdrant/qdrant\n",
    "```\n",
    "\n",
    "```shellscript\t\n",
    "python -m venv .venv\n",
    "source .venv/bin/activate\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt\n",
    "#!jupyter nbextension enable --py widgetsnbextension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo con Chroma DB para insertar y consultar\n",
    "import chromadb\n",
    "\n",
    "# Inicialización del cliente Chroma\n",
    "client = chromadb.Client()\n",
    "\n",
    "# Creación de una colección\n",
    "try:\n",
    "    client.delete_collection(\"basic_example\")\n",
    "except:\n",
    "    pass\n",
    "# Chroma Distance metric: https://docs.trychroma.com/usage-guide#changing-the-distance-function\n",
    "collection = client.create_collection(name=\"basic_example\", metadata={\"hnsw:space\": \"l2\"})\n",
    "\n",
    "# Creación de 4 vectores de dimensión 3\n",
    "vectores = [\n",
    "    [0.1, 0.1, 0.1],\n",
    "    [0.2, 0.2, 0.2],\n",
    "    [0.3, 0.3, 0.3],\n",
    "    [0.4, 0.4, 0.4]\n",
    "]\n",
    "metadatas = [\n",
    "    {\"color\": \"blue\"},\n",
    "    {\"color\": \"blue\"},\n",
    "    {\"color\": \"red\"},\n",
    "    {\"color\": \"red\"}\n",
    "]\n",
    "\n",
    "collection.upsert(ids=[\"1\", \"2\", \"3\", \"4\"], embeddings=vectores, metadatas=metadatas)\n",
    "\n",
    "q_embedding = [0.12, 0.12, 0.12]\n",
    "results = collection.query(query_embeddings=q_embedding, n_results=3, include = [\"metadatas\", \"embeddings\", \"distances\"],)\n",
    "print(f'Resultados para embedding: {q_embedding}')\n",
    "for i, id in enumerate(results['ids'][0]):\n",
    "    distance = results['distances'][0][i]\n",
    "    metadata = results['metadatas'][0][i]\n",
    "    vector = results['embeddings'][0][i]\n",
    "    print(f' - ID: {id}, Distance: {distance:.5f}, Metadata: {metadata}, Vector: [{vector[0]:.1f}, ...]')\n",
    "\n",
    "results = collection.query(query_embeddings=q_embedding, where={\"color\": \"red\"}, n_results=3, include = [\"metadatas\", \"embeddings\", \"distances\"],)\n",
    "print(f'Resultados para embedding: {q_embedding} con filtro color=red')\n",
    "for i, id in enumerate(results['ids'][0]):\n",
    "    distance = results['distances'][0][i]\n",
    "    metadata = results['metadatas'][0][i]\n",
    "    vector = results['embeddings'][0][i]\n",
    "    print(f' - ID: {id}, Distance: {distance:.5f}, Metadata: {metadata}, Vector: [{vector[0]:.1f}, ...]')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_json('datasets/star_wars_plots.json')\n",
    "print('Columns:', df.columns, ', Records:', df.shape[0])\n",
    "df.head()\n",
    "startwars_movies = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos embeddings del argumento de las películas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-minilm-l6-v2', device='cuda')\n",
    "#model = SentenceTransformer('all-mpnet-base-v2', device='cuda')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparamos los datos para almacenarlos en la BBDD Vectorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "CHUNK_WORDS = 200\n",
    "\n",
    "# Creamos chunks de texto de unas 170 palabras con un solape de 10 palabras\n",
    "def chunk_text(text, chunk_size=CHUNK_WORDS, overlap=CHUNK_WORDS//10):\n",
    "    '''\n",
    "    Divide el texto en chunks de un tamaño dado con un solape entre ellos.\n",
    "    Cada modelo solo puede procesar un número limitado de tokens, por lo que \n",
    "    es necesario dividir el texto en chunks.\n",
    "    1000 tokens son aproximadamente 750 palabras.\n",
    "    https://openai.com/pricing#language-models\n",
    "    '''\n",
    "    chunks = []\n",
    "    words = text.split()\n",
    "    for i in range(0, len(words), chunk_size-overlap):\n",
    "        chunks.append(' '.join(words[i:i+chunk_size]))\n",
    "    return chunks\n",
    "\n",
    "# Añadimos columnas plot_chunks y chunk_embeddings que serán arrays en  startwars_movies\n",
    "plot_embeddings = []\n",
    "for i, row in tqdm(startwars_movies.iterrows()):\n",
    "    plot_chunks = chunk_text(row['plot'])\n",
    "    embeddings = model.encode(plot_chunks).tolist()\n",
    "    plot_embeddings.append([{'chunk': chunk, 'embedding': embedding} for chunk, embedding in zip(plot_chunks, embeddings)])\n",
    "    print(i, row['title'], 'chunks:', len(plot_chunks))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un documento por cada chunk de texto de cada película con su embedding y metadatos\n",
    "\n",
    "vector_data = []\n",
    "i = 0\n",
    "for k, title in enumerate(startwars_movies['title'].tolist()):\n",
    "    #print(md)\n",
    "    for plot_chunk in plot_embeddings[k]:\n",
    "        metadata = dict(title=title)\n",
    "        i += 1\n",
    "        metadata['plot_chunk'] = plot_chunk['chunk'] \n",
    "        vector_data.append({\n",
    "            \"id\": i,\n",
    "            \"embedding\": plot_chunk['embedding'],\n",
    "            \"metadata\": metadata,\n",
    "        })\n",
    "\n",
    "for v in vector_data[:10]:\n",
    "    print(v['id'], v['metadata']['title'],'-', v['metadata']['plot_chunk'][:80])\n",
    "print('Vectors:', len(vector_data), 'Movies:', len(startwars_movies))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conectamos con Qdrant para crear una colección y alimentarla con los embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "\n",
    "qd = QdrantClient(url=\"http://localhost:6333\")\n",
    "\n",
    "MOVIES_COLLECTION = \"movies_sw\"\n",
    "\n",
    "qd.delete_collection(MOVIES_COLLECTION)\n",
    "# \"size\" is the dimension of the vectors, \"distance\" is the metric used to calculate the distance between vectors\n",
    "qd.create_collection(MOVIES_COLLECTION, VectorParams(size=model.get_sentence_embedding_dimension(), distance=Distance.COSINE))\n",
    "movies = qd.get_collection(MOVIES_COLLECTION)\n",
    "\n",
    "print(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.models import PointStruct\n",
    "\n",
    "points = list(map(lambda x: PointStruct(id=int(x['id']), vector=x['embedding'], payload=x['metadata']), vector_data))\n",
    "print('Points:', len(points), 'Movies:', len(startwars_movies))\n",
    "op = qd.upsert(\n",
    "    collection_name=MOVIES_COLLECTION,\n",
    "    wait=True,\n",
    "    points=points,\n",
    ")\n",
    "\n",
    "print(qd.get_collection(MOVIES_COLLECTION))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizamos búsquedas semánticas sobre la saga Star Wars (Spoilers warning!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "queries = [\n",
    "    'Anakin gana una carrera cuando era un niño',\n",
    "    'Los clones reciben la orden de ejecutar a los Jedi',\n",
    "    'Han Solo gana el Halcón Milenario en una partida de cartas',\n",
    "    #'Kylo Ren mata a su padre, Han Solo',\n",
    "    #'Palpatine es derrotado definitivamente por Rey',\n",
    "    # Less accurate queries\n",
    "    'Luke descubre que Darth Vader es su padre',\n",
    "    'Luke encuentra a Yoda y es entrenado como Jedi',\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    query_emb = model.encode(q)\n",
    "    results = qd.search(MOVIES_COLLECTION, query_vector=query_emb, limit=3)\n",
    "    print('Q:', q)\n",
    "    for r in results:\n",
    "        print('     ', r.score, ' => ', r.payload['title'])\n",
    "        print('     ', f'(id: {r.id})', r.payload['plot_chunk'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
